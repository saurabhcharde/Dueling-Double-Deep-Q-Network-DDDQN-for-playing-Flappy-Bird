# Dueling-Double-Deep-Q-Network-DDDQN-for-playing-Flappy-Bird
A DDDQN model for playing the game of Flappy Bird.

This DDDQN model was able to perform much better than the DQN and Double Q learning methods used alone.
It was able to acheive high scores in range of 70-80 which is significantly close to human score recorded on this game. In order to increase the complexity the frame rate was increased to 30 fps which is too fast for even a normal human player. Still the agent was able to score at the same rate without any significant performance drop.

Flappy Bird Game Environment: https://github.com/ntasfi/PyGame-Learning-Environment
